{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d41b1bcf-4c54-4a3f-9eac-8a1b6796d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d6bd3d-e8b9-442c-88d4-ef5dabadc9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 785 cols bc of labels row - only 28*28 = 784 pixels\n",
    "data = pd.read_csv('mnist_train.csv')\n",
    "data_test = pd.read_csv('mnist_test.csv')\n",
    "\n",
    "data = np.array(data)\n",
    "data_test = np.array(data_test)\n",
    "\n",
    "data = data.T\n",
    "data_test = data_test.T\n",
    "\n",
    "def preprocess_data(X):\n",
    "    \"\"\"Preprocess the input data\"\"\"\n",
    "    # Scale pixels to [0, 1] range\n",
    "    X = X / 255.0\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61deec0c-72ea-408c-bb11-37660430cc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 784)\n",
      "[7 2 1 ... 4 5 6]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_train = data[1:data[0].size].T # 2D Array: each row (array) is a picture\n",
    "x_test = data_test[1:data[0].size].T # 2D Array: each row (array) is a picture\n",
    "x_train = preprocess_data(x_train)\n",
    "x_test = preprocess_data(x_test)\n",
    "x_labels = data[0] # Array: each number is the correct label for the corresponding index in x_train\n",
    "x_test_labels = data_test[0]\n",
    "print(x_train.shape)\n",
    "print(x_test_labels)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df70431d-b5b2-4ade-9a75-40bdbb3bec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters for every layer\n",
    "# Weights & biases\n",
    "def init_params():\n",
    "    W_1 = np.random.randn(16, 784) * np.sqrt(2.0/784) # Edges from layer 1 to layer 2\n",
    "    B_1 = np.zeros(16) # Biases for layer 2\n",
    "    W_2 = np.random.randn(10, 16) * np.sqrt(2.0/32) # Edges from layer 2 to layer 3\n",
    "    B_2 = np.zeros(10) # Biases for layer 3\n",
    "    return W_1, B_1, W_2, B_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68edbc96-66a8-4343-bd2f-d43a97c82dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    # Ensure input is at least 1D\n",
    "    Z = np.atleast_1d(Z)\n",
    "    \n",
    "    # Shift values by max for numerical stability\n",
    "    Z_shifted = Z - np.max(Z, axis=-1, keepdims=True)\n",
    "    \n",
    "    # Avoid overflow\n",
    "    exp_Z = np.exp(np.clip(Z_shifted, -709, 709))  # np.log(np.finfo(np.float64).max) â‰ˆ 709\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    sum_exp_Z = np.sum(exp_Z, axis=-1, keepdims=True)\n",
    "    sum_exp_Z = np.maximum(sum_exp_Z, np.finfo(float).tiny)\n",
    "    \n",
    "    softmax_output = exp_Z / sum_exp_Z\n",
    "    \n",
    "    # Ensure probabilities sum to 1\n",
    "    softmax_output = softmax_output / np.sum(softmax_output, axis=-1, keepdims=True)\n",
    "    \n",
    "    return softmax_output\n",
    "\n",
    "# Cross-entropy cost function\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    # y_true is a one-hot encoded vector (e.g., [0, 1, 0, ...])\n",
    "    # y_pred is the softmax output\n",
    "    epsilon = 1e-10  # To avoid log(0)\n",
    "    return -np.sum(y_true * np.log(y_pred + epsilon))  # Sum over classes\n",
    "\n",
    "# Cost function\n",
    "def get_cost(Z_2, i):\n",
    "    error_arr = np.zeros(10)\n",
    "    error_arr[x_labels[i]] = 1 # Corresponding to one_picture\n",
    "    cost = cross_entropy_loss(error_arr, Z_2)\n",
    "    return cost, error_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c67dada-d110-49e9-9a6f-18236a1c2a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Forward Propagation\n",
    "# Z_1: neurons in hidden layer\n",
    "# Z_2: neurons in output layer\n",
    "def forward_prop(i, W_1, B_1, W_2, B_2):\n",
    "    one_picture = x_train[i] # A single sample picture\n",
    "    \n",
    "    Z_1 = W_1.dot(one_picture) + B_1\n",
    "    Z_1 = ReLU(Z_1)\n",
    "    Z_2 = W_2.dot(Z_1) + B_2\n",
    "    Z_2 = softmax(Z_2)\n",
    "    return Z_1, Z_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa0d30b-c214-48d0-b80d-7c2875ec4abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "def back_prop(Z_1, Z_2, W_2, i):\n",
    "    one_picture = x_train[i]\n",
    "    error_arr = get_cost(Z_2, i)[1]\n",
    "    \n",
    "    dZ_2 = Z_2 - error_arr\n",
    "    dW_2 = np.outer(dZ_2, Z_1)\n",
    "    dB_2 = dZ_2\n",
    "    \n",
    "    dZ_1 = W_2.T.dot(dZ_2)\n",
    "    dZ_1 *= (Z_1 > 0)\n",
    "    dW_1 = np.outer(dZ_1, one_picture)\n",
    "    dB_1 = dZ_1\n",
    "    \n",
    "    return dW_1, dB_1, dZ_1, dW_2, dB_2, dZ_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f28944ec-50da-4638-b21c-0fa7e67b9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters\n",
    "def update_params(W_2, B_2, W_1, B_1, dW_2, dB_2, dW_1, dB_1, learning_rate):\n",
    "    W_2 -= dW_2 * learning_rate\n",
    "    B_2 -= dB_2 * learning_rate\n",
    "    W_1 -= dW_1 * learning_rate\n",
    "    B_1 -= dB_1 * learning_rate\n",
    "    return W_1, B_1, W_2, B_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e8ce842-4f1d-4301-8a28-f7bab568e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, learning_rate):\n",
    "    W_1, B_1, W_2, B_2 = init_params()\n",
    "    leng = x_train.shape[0]\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        #np.random.shuffle(x_train)\n",
    "\n",
    "        #learning_rate *= 0.9 # Varying learning rate    \n",
    "        \n",
    "        iteration = 0\n",
    "        for j in range(leng):\n",
    "            iteration = j\n",
    "            Z_1, Z_2 = forward_prop(j, W_1, B_1, W_2, B_2)\n",
    "            dW_1, dB_1, dZ_1, dW_2, dB_2, dZ_2 = back_prop(Z_1, Z_2, W_2, j)\n",
    "            W_1, B_1, W_2, B_2 = update_params(W_2, B_2, W_1, B_1, dW_2, dB_2, dW_1, dB_1, learning_rate)    \n",
    "        if i % 1 == 0:\n",
    "            print(f\"Epoch {i}: cost = {get_cost(Z_2, iteration)[0]}, LR = {learning_rate}\")\n",
    "    return W_1, B_1, W_2, B_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87fafdd6-8fb3-480b-93bb-512a30787d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W_1, B_1, W_2, B_2):\n",
    "    \"\"\"\n",
    "    Make predictions for input images\n",
    "    \n",
    "    Parameters:\n",
    "    X: numpy array of shape (n_samples, 784) - input images\n",
    "    Returns: tuple (predictions, probabilities)\n",
    "    - predictions: predicted digit for each image\n",
    "    - probabilities: softmax probabilities for each digit\n",
    "    \"\"\"\n",
    "    # Ensure input is properly scaled\n",
    "    X = X / 255.0 if X.max() > 1 else X\n",
    "    \n",
    "    # Forward pass\n",
    "    Z_1 = X.dot(W_1.T) + B_1\n",
    "    A_1 = np.maximum(0, Z_1)  # ReLU\n",
    "    Z_2 = A_1.dot(W_2.T) + B_2\n",
    "    probabilities = softmax(Z_2)\n",
    "\n",
    "    \"\"\"\n",
    "    one_picture = x_train[i] # A single sample picture\n",
    "    \n",
    "    Z_1 = W_1.dot(one_picture) + B_1\n",
    "    Z_1 = ReLU(Z_1)\n",
    "    Z_2 = W_2.dot(Z_1) + B_2\n",
    "    Z_2 = softmax(Z_2)\n",
    "    return Z_1, Z_2\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Get predicted digit (class with highest probability)\n",
    "    predictions = np.argmax(probabilities, axis=1)\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b013cc03-badb-4b93-8c25-1ec0ea292958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: cost = 0.6962699358761829, LR = 0.0001\n",
      "Epoch 1: cost = 0.35793597831221247, LR = 0.0001\n",
      "Epoch 2: cost = 0.2715497263225102, LR = 0.0001\n",
      "Epoch 3: cost = 0.23961916963551874, LR = 0.0001\n",
      "Epoch 4: cost = 0.22322153759416474, LR = 0.0001\n",
      "Epoch 5: cost = 0.21222355425967618, LR = 0.0001\n",
      "Epoch 6: cost = 0.20288310933189135, LR = 0.0001\n",
      "Epoch 7: cost = 0.19498841053640523, LR = 0.0001\n",
      "Epoch 8: cost = 0.18834326267499577, LR = 0.0001\n",
      "Epoch 9: cost = 0.18766957834494585, LR = 0.0001\n",
      "Epoch 10: cost = 0.18645251461354773, LR = 0.0001\n",
      "Epoch 11: cost = 0.18366244296723616, LR = 0.0001\n",
      "Epoch 12: cost = 0.1812964138592144, LR = 0.0001\n",
      "Epoch 13: cost = 0.1784986440622924, LR = 0.0001\n",
      "Epoch 14: cost = 0.1759904243894083, LR = 0.0001\n",
      "Epoch 15: cost = 0.17386795129564697, LR = 0.0001\n",
      "Epoch 16: cost = 0.1721453497788862, LR = 0.0001\n",
      "Epoch 17: cost = 0.17142955942434404, LR = 0.0001\n",
      "Epoch 18: cost = 0.17060594364354195, LR = 0.0001\n",
      "Epoch 19: cost = 0.16883235456903195, LR = 0.0001\n",
      "Epoch 20: cost = 0.1668111365956011, LR = 0.0001\n",
      "Epoch 21: cost = 0.16516794783058333, LR = 0.0001\n",
      "Epoch 22: cost = 0.16370541201475458, LR = 0.0001\n",
      "Epoch 23: cost = 0.16193363041531597, LR = 0.0001\n",
      "Epoch 24: cost = 0.15978950381068918, LR = 0.0001\n",
      "Epoch 25: cost = 0.15722928541284836, LR = 0.0001\n",
      "Epoch 26: cost = 0.1542496558767563, LR = 0.0001\n",
      "Epoch 27: cost = 0.1520434605709591, LR = 0.0001\n",
      "Epoch 28: cost = 0.14925832406615563, LR = 0.0001\n",
      "Epoch 29: cost = 0.14730985005339003, LR = 0.0001\n",
      "Epoch 30: cost = 0.145187692714973, LR = 0.0001\n",
      "Epoch 31: cost = 0.14236128870968479, LR = 0.0001\n",
      "Epoch 32: cost = 0.13996756050897524, LR = 0.0001\n",
      "Epoch 33: cost = 0.13709405184550863, LR = 0.0001\n",
      "Epoch 34: cost = 0.1340876059839669, LR = 0.0001\n",
      "Epoch 35: cost = 0.13106344258998692, LR = 0.0001\n",
      "Epoch 36: cost = 0.12834760999823966, LR = 0.0001\n",
      "Epoch 37: cost = 0.1257072831426181, LR = 0.0001\n",
      "Epoch 38: cost = 0.12302761616145949, LR = 0.0001\n",
      "Epoch 39: cost = 0.11912162081282807, LR = 0.0001\n",
      "Epoch 40: cost = 0.11559291186843745, LR = 0.0001\n",
      "Epoch 41: cost = 0.11196591079313527, LR = 0.0001\n",
      "Epoch 42: cost = 0.10823130175128055, LR = 0.0001\n",
      "Epoch 43: cost = 0.10421888966402681, LR = 0.0001\n",
      "Epoch 44: cost = 0.10027044979773601, LR = 0.0001\n",
      "Epoch 45: cost = 0.09661855566509933, LR = 0.0001\n",
      "Epoch 46: cost = 0.09269033964779458, LR = 0.0001\n",
      "Epoch 47: cost = 0.0892731605656513, LR = 0.0001\n",
      "Epoch 48: cost = 0.08540088229602621, LR = 0.0001\n",
      "Epoch 49: cost = 0.0818349430718872, LR = 0.0001\n",
      "Epoch 50: cost = 0.07782348057578915, LR = 0.0001\n",
      "Epoch 51: cost = 0.07404456223370723, LR = 0.0001\n",
      "Epoch 52: cost = 0.07054152414234381, LR = 0.0001\n",
      "Epoch 53: cost = 0.06674542917257871, LR = 0.0001\n",
      "Epoch 54: cost = 0.06314239652762271, LR = 0.0001\n",
      "Epoch 55: cost = 0.06012141448430108, LR = 0.0001\n",
      "Epoch 56: cost = 0.05788838223885792, LR = 0.0001\n",
      "Epoch 57: cost = 0.05558918926794908, LR = 0.0001\n",
      "Epoch 58: cost = 0.0535432808247684, LR = 0.0001\n",
      "Epoch 59: cost = 0.051455373567059814, LR = 0.0001\n",
      "Epoch 60: cost = 0.04949279603657354, LR = 0.0001\n",
      "Epoch 61: cost = 0.04768565764911277, LR = 0.0001\n",
      "Epoch 62: cost = 0.04604940687132743, LR = 0.0001\n",
      "Epoch 63: cost = 0.04438777177875868, LR = 0.0001\n",
      "Epoch 64: cost = 0.0429687026554672, LR = 0.0001\n",
      "Epoch 65: cost = 0.04159156743719163, LR = 0.0001\n",
      "Epoch 66: cost = 0.04002280762402302, LR = 0.0001\n",
      "Epoch 67: cost = 0.03868605443268416, LR = 0.0001\n",
      "Epoch 68: cost = 0.0372607117862317, LR = 0.0001\n",
      "Epoch 69: cost = 0.03589640473647245, LR = 0.0001\n",
      "Epoch 70: cost = 0.03462790645376238, LR = 0.0001\n",
      "Epoch 71: cost = 0.033331876267740014, LR = 0.0001\n",
      "Epoch 72: cost = 0.032122349924858344, LR = 0.0001\n",
      "Epoch 73: cost = 0.03094843902155175, LR = 0.0001\n",
      "Epoch 74: cost = 0.029892528643705073, LR = 0.0001\n",
      "Epoch 75: cost = 0.02891026784011116, LR = 0.0001\n",
      "Epoch 76: cost = 0.028046742139491203, LR = 0.0001\n",
      "Epoch 77: cost = 0.027066318761219496, LR = 0.0001\n",
      "Epoch 78: cost = 0.026247836702368302, LR = 0.0001\n",
      "Epoch 79: cost = 0.025449319289547728, LR = 0.0001\n",
      "Epoch 80: cost = 0.024674345850612175, LR = 0.0001\n",
      "Epoch 81: cost = 0.024085510410836113, LR = 0.0001\n",
      "Epoch 82: cost = 0.023436547694500997, LR = 0.0001\n",
      "Epoch 83: cost = 0.022782737711233972, LR = 0.0001\n",
      "Epoch 84: cost = 0.02218292247375577, LR = 0.0001\n",
      "Epoch 85: cost = 0.021585412200629966, LR = 0.0001\n",
      "Epoch 86: cost = 0.021102571753425805, LR = 0.0001\n",
      "Epoch 87: cost = 0.020646643734641718, LR = 0.0001\n",
      "Epoch 88: cost = 0.02028223226147413, LR = 0.0001\n",
      "Epoch 89: cost = 0.019987302638789187, LR = 0.0001\n",
      "Epoch 90: cost = 0.019600223069139885, LR = 0.0001\n",
      "Epoch 91: cost = 0.01929645896958593, LR = 0.0001\n",
      "Epoch 92: cost = 0.018872404708399834, LR = 0.0001\n",
      "Epoch 93: cost = 0.0184875731929016, LR = 0.0001\n",
      "Epoch 94: cost = 0.0181893552265153, LR = 0.0001\n",
      "Epoch 95: cost = 0.017836778549311032, LR = 0.0001\n",
      "Epoch 96: cost = 0.017614511266171563, LR = 0.0001\n",
      "Epoch 97: cost = 0.017292558833218365, LR = 0.0001\n",
      "Epoch 98: cost = 0.017036433394810653, LR = 0.0001\n",
      "Epoch 99: cost = 0.016885703895676327, LR = 0.0001\n",
      "Epoch 100: cost = 0.01662155796633511, LR = 0.0001\n",
      "Epoch 101: cost = 0.01644672107048089, LR = 0.0001\n",
      "Epoch 102: cost = 0.016246497132010894, LR = 0.0001\n",
      "Epoch 103: cost = 0.016146899153795864, LR = 0.0001\n",
      "Epoch 104: cost = 0.01590069978914961, LR = 0.0001\n",
      "Epoch 105: cost = 0.015778561012263784, LR = 0.0001\n",
      "Epoch 106: cost = 0.01555944450780599, LR = 0.0001\n",
      "Epoch 107: cost = 0.015417858691772979, LR = 0.0001\n",
      "Epoch 108: cost = 0.015270417975529308, LR = 0.0001\n",
      "Epoch 109: cost = 0.015130658002534852, LR = 0.0001\n",
      "Epoch 110: cost = 0.015060982795459144, LR = 0.0001\n",
      "Epoch 111: cost = 0.014904055110769976, LR = 0.0001\n",
      "Epoch 112: cost = 0.014837214447446246, LR = 0.0001\n",
      "Epoch 113: cost = 0.014698813943370652, LR = 0.0001\n",
      "Epoch 114: cost = 0.014567491070030428, LR = 0.0001\n",
      "Epoch 115: cost = 0.01441533761381804, LR = 0.0001\n",
      "Epoch 116: cost = 0.014402576588488366, LR = 0.0001\n",
      "Epoch 117: cost = 0.0142628565145679, LR = 0.0001\n",
      "Epoch 118: cost = 0.014179341057048711, LR = 0.0001\n",
      "Epoch 119: cost = 0.01411282034600237, LR = 0.0001\n",
      "Epoch 120: cost = 0.013965301346009418, LR = 0.0001\n",
      "Epoch 121: cost = 0.013889718502850262, LR = 0.0001\n",
      "Epoch 122: cost = 0.01384808475991912, LR = 0.0001\n",
      "Epoch 123: cost = 0.013797506743774836, LR = 0.0001\n",
      "Epoch 124: cost = 0.013752804107229392, LR = 0.0001\n",
      "Epoch 125: cost = 0.013677952957527575, LR = 0.0001\n",
      "Epoch 126: cost = 0.013692256024946965, LR = 0.0001\n",
      "Epoch 127: cost = 0.013644636945610918, LR = 0.0001\n",
      "Epoch 128: cost = 0.013656707428114423, LR = 0.0001\n",
      "Epoch 129: cost = 0.013637306059472368, LR = 0.0001\n",
      "Epoch 130: cost = 0.013676095555707899, LR = 0.0001\n",
      "Epoch 131: cost = 0.013715924625525684, LR = 0.0001\n",
      "Epoch 132: cost = 0.013774791539633182, LR = 0.0001\n",
      "Epoch 133: cost = 0.013868495949234288, LR = 0.0001\n",
      "Epoch 134: cost = 0.01390999446702123, LR = 0.0001\n",
      "Epoch 135: cost = 0.013985601057870209, LR = 0.0001\n",
      "Epoch 136: cost = 0.014123195499044236, LR = 0.0001\n",
      "Epoch 137: cost = 0.01416164845856538, LR = 0.0001\n",
      "Epoch 138: cost = 0.014270369402456903, LR = 0.0001\n",
      "Epoch 139: cost = 0.014314239403167402, LR = 0.0001\n",
      "Epoch 140: cost = 0.01445266512092538, LR = 0.0001\n",
      "Epoch 141: cost = 0.014562337289276616, LR = 0.0001\n",
      "Epoch 142: cost = 0.014576198349706289, LR = 0.0001\n",
      "Epoch 143: cost = 0.014578151260456315, LR = 0.0001\n",
      "Epoch 144: cost = 0.014604070672600302, LR = 0.0001\n",
      "Epoch 145: cost = 0.014644910683228079, LR = 0.0001\n",
      "Epoch 146: cost = 0.01463385267778139, LR = 0.0001\n",
      "Epoch 147: cost = 0.01473663888409277, LR = 0.0001\n",
      "Epoch 148: cost = 0.014872398350791915, LR = 0.0001\n",
      "Epoch 149: cost = 0.015036681278924725, LR = 0.0001\n",
      "Epoch 150: cost = 0.015115346921372614, LR = 0.0001\n",
      "Epoch 151: cost = 0.0151789183926119, LR = 0.0001\n",
      "Epoch 152: cost = 0.015360076939616232, LR = 0.0001\n",
      "Epoch 153: cost = 0.015567939213611565, LR = 0.0001\n",
      "Epoch 154: cost = 0.01570099296551964, LR = 0.0001\n",
      "Epoch 155: cost = 0.01582469602925153, LR = 0.0001\n",
      "Epoch 156: cost = 0.015958345854528953, LR = 0.0001\n",
      "Epoch 157: cost = 0.016043052043276305, LR = 0.0001\n",
      "Epoch 158: cost = 0.016230285703658552, LR = 0.0001\n",
      "Epoch 159: cost = 0.016218499777416205, LR = 0.0001\n",
      "Epoch 160: cost = 0.01624263507350487, LR = 0.0001\n",
      "Epoch 161: cost = 0.016193435470047035, LR = 0.0001\n",
      "Epoch 162: cost = 0.016242220370477112, LR = 0.0001\n",
      "Epoch 163: cost = 0.016247375081331533, LR = 0.0001\n",
      "Epoch 164: cost = 0.01625162051222665, LR = 0.0001\n",
      "Epoch 165: cost = 0.016402528893958473, LR = 0.0001\n",
      "Epoch 166: cost = 0.016396228730707917, LR = 0.0001\n",
      "Epoch 167: cost = 0.016480031101018134, LR = 0.0001\n",
      "Epoch 168: cost = 0.016456621697977552, LR = 0.0001\n",
      "Epoch 169: cost = 0.016532189856732046, LR = 0.0001\n",
      "Epoch 170: cost = 0.01670843484182158, LR = 0.0001\n",
      "Epoch 171: cost = 0.016723736013975497, LR = 0.0001\n",
      "Epoch 172: cost = 0.016883708133809357, LR = 0.0001\n",
      "Epoch 173: cost = 0.016993162186143013, LR = 0.0001\n",
      "Epoch 174: cost = 0.01709855449383113, LR = 0.0001\n",
      "Epoch 175: cost = 0.017196921925524588, LR = 0.0001\n",
      "Epoch 176: cost = 0.017369172761923585, LR = 0.0001\n",
      "Epoch 177: cost = 0.017493224343739025, LR = 0.0001\n",
      "Epoch 178: cost = 0.017603091269660538, LR = 0.0001\n",
      "Epoch 179: cost = 0.01781846536482213, LR = 0.0001\n",
      "Epoch 180: cost = 0.017922087593544203, LR = 0.0001\n",
      "Epoch 181: cost = 0.018147952744712963, LR = 0.0001\n",
      "Epoch 182: cost = 0.018364754812152394, LR = 0.0001\n",
      "Epoch 183: cost = 0.018633001541655102, LR = 0.0001\n",
      "Epoch 184: cost = 0.01887013659166378, LR = 0.0001\n",
      "Epoch 185: cost = 0.019221634927075158, LR = 0.0001\n",
      "Epoch 186: cost = 0.019507208140630523, LR = 0.0001\n",
      "Epoch 187: cost = 0.019551375656040038, LR = 0.0001\n",
      "Epoch 188: cost = 0.019855198029369775, LR = 0.0001\n",
      "Epoch 189: cost = 0.02010733498551308, LR = 0.0001\n",
      "Epoch 190: cost = 0.020340934979715303, LR = 0.0001\n",
      "Epoch 191: cost = 0.02055363899317382, LR = 0.0001\n",
      "Epoch 192: cost = 0.020821779446854555, LR = 0.0001\n",
      "Epoch 193: cost = 0.02089598958187033, LR = 0.0001\n",
      "Epoch 194: cost = 0.02108713024286312, LR = 0.0001\n",
      "Epoch 195: cost = 0.021266489812867995, LR = 0.0001\n",
      "Epoch 196: cost = 0.021271755250165565, LR = 0.0001\n",
      "Epoch 197: cost = 0.021503324535051573, LR = 0.0001\n",
      "Epoch 198: cost = 0.021703653572807582, LR = 0.0001\n",
      "Epoch 199: cost = 0.021974503910535233, LR = 0.0001\n",
      "Epoch 200: cost = 0.022264311859455693, LR = 0.0001\n",
      "Epoch 201: cost = 0.022461830394110073, LR = 0.0001\n",
      "Epoch 202: cost = 0.02277529982118754, LR = 0.0001\n",
      "Epoch 203: cost = 0.02280799336688937, LR = 0.0001\n",
      "Epoch 204: cost = 0.023025819171487626, LR = 0.0001\n",
      "Epoch 205: cost = 0.023209273141451457, LR = 0.0001\n",
      "Epoch 206: cost = 0.02358668577417051, LR = 0.0001\n",
      "Epoch 207: cost = 0.023594799366712774, LR = 0.0001\n",
      "Epoch 208: cost = 0.023912655658223706, LR = 0.0001\n",
      "Epoch 209: cost = 0.023985167997934126, LR = 0.0001\n",
      "Epoch 210: cost = 0.023898366641983797, LR = 0.0001\n",
      "Epoch 211: cost = 0.023928383526279264, LR = 0.0001\n",
      "Epoch 212: cost = 0.024014439198323558, LR = 0.0001\n",
      "Epoch 213: cost = 0.024038088110648018, LR = 0.0001\n",
      "Epoch 214: cost = 0.02408043642613874, LR = 0.0001\n",
      "Epoch 215: cost = 0.024001800630537962, LR = 0.0001\n",
      "Epoch 216: cost = 0.02377803511898521, LR = 0.0001\n",
      "Epoch 217: cost = 0.02392814341079116, LR = 0.0001\n",
      "Epoch 218: cost = 0.023797696993969032, LR = 0.0001\n",
      "Epoch 219: cost = 0.023835803357769653, LR = 0.0001\n",
      "Epoch 220: cost = 0.023660083883383653, LR = 0.0001\n",
      "Epoch 221: cost = 0.023688395253640644, LR = 0.0001\n",
      "Epoch 222: cost = 0.023527437090626824, LR = 0.0001\n",
      "Epoch 223: cost = 0.02343512898117235, LR = 0.0001\n",
      "Epoch 224: cost = 0.023442998969131115, LR = 0.0001\n",
      "Epoch 225: cost = 0.023393834639281148, LR = 0.0001\n",
      "Epoch 226: cost = 0.023295876980309615, LR = 0.0001\n",
      "Epoch 227: cost = 0.023307169411035902, LR = 0.0001\n",
      "Epoch 228: cost = 0.02331782069041292, LR = 0.0001\n",
      "Epoch 229: cost = 0.023332415811800417, LR = 0.0001\n",
      "Epoch 230: cost = 0.023355462708846905, LR = 0.0001\n",
      "Epoch 231: cost = 0.023466297202891957, LR = 0.0001\n",
      "Epoch 232: cost = 0.023528156246978155, LR = 0.0001\n",
      "Epoch 233: cost = 0.023568302877216625, LR = 0.0001\n",
      "Epoch 234: cost = 0.023426975481442402, LR = 0.0001\n",
      "Epoch 235: cost = 0.023635122719404763, LR = 0.0001\n",
      "Epoch 236: cost = 0.023666684817649362, LR = 0.0001\n",
      "Epoch 237: cost = 0.023475485611063333, LR = 0.0001\n",
      "Epoch 238: cost = 0.02379111404769012, LR = 0.0001\n",
      "Epoch 239: cost = 0.02357761321316076, LR = 0.0001\n",
      "Epoch 240: cost = 0.023688623400694338, LR = 0.0001\n",
      "Epoch 241: cost = 0.02342585541783485, LR = 0.0001\n",
      "Epoch 242: cost = 0.023626145913736178, LR = 0.0001\n",
      "Epoch 243: cost = 0.023414688430835547, LR = 0.0001\n",
      "Epoch 244: cost = 0.023516887436443038, LR = 0.0001\n",
      "Epoch 245: cost = 0.023615739231279322, LR = 0.0001\n",
      "Epoch 246: cost = 0.02341463761476759, LR = 0.0001\n",
      "Epoch 247: cost = 0.023496112419501388, LR = 0.0001\n",
      "Epoch 248: cost = 0.023475290141392526, LR = 0.0001\n",
      "Epoch 249: cost = 0.02346247838249217, LR = 0.0001\n",
      "Epoch 250: cost = 0.02354888036170715, LR = 0.0001\n",
      "Epoch 251: cost = 0.02345266596547202, LR = 0.0001\n",
      "Epoch 252: cost = 0.023582402041747285, LR = 0.0001\n",
      "Epoch 253: cost = 0.023651601478531882, LR = 0.0001\n",
      "Epoch 254: cost = 0.023541682459638516, LR = 0.0001\n",
      "Epoch 255: cost = 0.023557149521432355, LR = 0.0001\n",
      "Epoch 256: cost = 0.02362892036187046, LR = 0.0001\n",
      "Epoch 257: cost = 0.02341144608706625, LR = 0.0001\n",
      "Epoch 258: cost = 0.02336675382277554, LR = 0.0001\n",
      "Epoch 259: cost = 0.023538590729305114, LR = 0.0001\n",
      "Epoch 260: cost = 0.023445118656657056, LR = 0.0001\n",
      "Epoch 261: cost = 0.02336985989246029, LR = 0.0001\n",
      "Epoch 262: cost = 0.023201624034124405, LR = 0.0001\n",
      "Epoch 263: cost = 0.02345621448109392, LR = 0.0001\n",
      "Epoch 264: cost = 0.02317437645468862, LR = 0.0001\n",
      "Epoch 265: cost = 0.023284679335168913, LR = 0.0001\n",
      "Epoch 266: cost = 0.023261368415545214, LR = 0.0001\n",
      "Epoch 267: cost = 0.023335659442370444, LR = 0.0001\n",
      "Epoch 268: cost = 0.023392046990062292, LR = 0.0001\n",
      "Epoch 269: cost = 0.023348235028257173, LR = 0.0001\n",
      "Epoch 270: cost = 0.02342370783308003, LR = 0.0001\n",
      "Epoch 271: cost = 0.023548883742795176, LR = 0.0001\n",
      "Epoch 272: cost = 0.02357422683655559, LR = 0.0001\n",
      "Epoch 273: cost = 0.023450209029822307, LR = 0.0001\n",
      "Epoch 274: cost = 0.02355874815416964, LR = 0.0001\n",
      "Epoch 275: cost = 0.023350299642908523, LR = 0.0001\n",
      "Epoch 276: cost = 0.023460781120349456, LR = 0.0001\n",
      "Epoch 277: cost = 0.023325207805741325, LR = 0.0001\n",
      "Epoch 278: cost = 0.023487734911601357, LR = 0.0001\n",
      "Epoch 279: cost = 0.023461810156845193, LR = 0.0001\n",
      "Epoch 280: cost = 0.023582842396282108, LR = 0.0001\n",
      "Epoch 281: cost = 0.023761396143030047, LR = 0.0001\n",
      "Epoch 282: cost = 0.023667082338038097, LR = 0.0001\n",
      "Epoch 283: cost = 0.023908812560361387, LR = 0.0001\n",
      "Epoch 284: cost = 0.023979317505741823, LR = 0.0001\n",
      "Epoch 285: cost = 0.02407542608502106, LR = 0.0001\n",
      "Epoch 286: cost = 0.024160938541770375, LR = 0.0001\n",
      "Epoch 287: cost = 0.02431961751877356, LR = 0.0001\n",
      "Epoch 288: cost = 0.024142875367648, LR = 0.0001\n",
      "Epoch 289: cost = 0.02426317250612063, LR = 0.0001\n",
      "Epoch 290: cost = 0.024369809893576313, LR = 0.0001\n",
      "Epoch 291: cost = 0.024399067750051903, LR = 0.0001\n",
      "Epoch 292: cost = 0.024429923615214538, LR = 0.0001\n",
      "Epoch 293: cost = 0.024599111406778815, LR = 0.0001\n",
      "Epoch 294: cost = 0.024549598493849, LR = 0.0001\n",
      "Epoch 295: cost = 0.024714147440750484, LR = 0.0001\n",
      "Epoch 296: cost = 0.024679405862967848, LR = 0.0001\n",
      "Epoch 297: cost = 0.024953820559499747, LR = 0.0001\n",
      "Epoch 298: cost = 0.02456343947071561, LR = 0.0001\n",
      "Epoch 299: cost = 0.02465989112048907, LR = 0.0001\n",
      "Epoch 300: cost = 0.02480059150181931, LR = 0.0001\n",
      "Epoch 301: cost = 0.024894545097659503, LR = 0.0001\n",
      "Epoch 302: cost = 0.02488744324407056, LR = 0.0001\n",
      "Epoch 303: cost = 0.024888489195398954, LR = 0.0001\n",
      "Epoch 304: cost = 0.024781045058723892, LR = 0.0001\n",
      "Epoch 305: cost = 0.024797983814403596, LR = 0.0001\n",
      "Epoch 306: cost = 0.024978709679894056, LR = 0.0001\n",
      "Epoch 307: cost = 0.02507167448420335, LR = 0.0001\n",
      "Epoch 308: cost = 0.024964147486689757, LR = 0.0001\n",
      "Epoch 309: cost = 0.024918009568485895, LR = 0.0001\n",
      "Epoch 310: cost = 0.025062880961434598, LR = 0.0001\n",
      "Epoch 311: cost = 0.02518088814597753, LR = 0.0001\n",
      "Epoch 312: cost = 0.025214197302623646, LR = 0.0001\n",
      "Epoch 313: cost = 0.024994069122080652, LR = 0.0001\n",
      "Epoch 314: cost = 0.025217133790661584, LR = 0.0001\n",
      "Epoch 315: cost = 0.025066419227745645, LR = 0.0001\n",
      "Epoch 316: cost = 0.025244956368763238, LR = 0.0001\n",
      "Epoch 317: cost = 0.025080176043305587, LR = 0.0001\n",
      "Epoch 318: cost = 0.025003536044997787, LR = 0.0001\n",
      "Epoch 319: cost = 0.02492032763412367, LR = 0.0001\n",
      "Epoch 320: cost = 0.025097161082458058, LR = 0.0001\n",
      "Epoch 321: cost = 0.02493261016376694, LR = 0.0001\n",
      "Epoch 322: cost = 0.024827612589345217, LR = 0.0001\n",
      "Epoch 323: cost = 0.024799764282133128, LR = 0.0001\n",
      "Epoch 324: cost = 0.02472314723801437, LR = 0.0001\n",
      "Epoch 325: cost = 0.02454915527463755, LR = 0.0001\n",
      "Epoch 326: cost = 0.02453919659892284, LR = 0.0001\n",
      "Epoch 327: cost = 0.024570251602226853, LR = 0.0001\n",
      "Epoch 328: cost = 0.024389224083459848, LR = 0.0001\n",
      "Epoch 329: cost = 0.024596602775413434, LR = 0.0001\n",
      "Epoch 330: cost = 0.02439208368478747, LR = 0.0001\n",
      "Epoch 331: cost = 0.02436338853989535, LR = 0.0001\n",
      "Epoch 332: cost = 0.024384611939931713, LR = 0.0001\n",
      "Epoch 333: cost = 0.024354643777275743, LR = 0.0001\n",
      "Epoch 334: cost = 0.024255167360386864, LR = 0.0001\n",
      "Epoch 335: cost = 0.024236539714278492, LR = 0.0001\n",
      "Epoch 336: cost = 0.024211969391412545, LR = 0.0001\n",
      "Epoch 337: cost = 0.024123664971686182, LR = 0.0001\n",
      "Epoch 338: cost = 0.023874269845805242, LR = 0.0001\n",
      "Epoch 339: cost = 0.02404634386608399, LR = 0.0001\n",
      "Epoch 340: cost = 0.023900908381385245, LR = 0.0001\n",
      "Epoch 341: cost = 0.023861514334348313, LR = 0.0001\n",
      "Epoch 342: cost = 0.023857483160050548, LR = 0.0001\n",
      "Epoch 343: cost = 0.023766743812000446, LR = 0.0001\n",
      "Epoch 344: cost = 0.0236295875885721, LR = 0.0001\n",
      "Epoch 345: cost = 0.023553393927169066, LR = 0.0001\n",
      "Epoch 346: cost = 0.023321978705222048, LR = 0.0001\n",
      "Epoch 347: cost = 0.023458164597235417, LR = 0.0001\n",
      "Epoch 348: cost = 0.0234448334853515, LR = 0.0001\n",
      "Epoch 349: cost = 0.023282809367629873, LR = 0.0001\n",
      "Epoch 350: cost = 0.023249690743774462, LR = 0.0001\n",
      "Epoch 351: cost = 0.023129584262787373, LR = 0.0001\n",
      "Epoch 352: cost = 0.022954976875853454, LR = 0.0001\n",
      "Epoch 353: cost = 0.022974338470146752, LR = 0.0001\n",
      "Epoch 354: cost = 0.022802442725066478, LR = 0.0001\n",
      "Epoch 355: cost = 0.022651675063764545, LR = 0.0001\n",
      "Epoch 356: cost = 0.022620791085612164, LR = 0.0001\n",
      "Epoch 357: cost = 0.02268330281253702, LR = 0.0001\n",
      "Epoch 358: cost = 0.022712396055749533, LR = 0.0001\n",
      "Epoch 359: cost = 0.022630059713895874, LR = 0.0001\n",
      "Epoch 360: cost = 0.022629355030114425, LR = 0.0001\n",
      "Epoch 361: cost = 0.022516560547049955, LR = 0.0001\n",
      "Epoch 362: cost = 0.02252216002046439, LR = 0.0001\n",
      "Epoch 363: cost = 0.02254131263312496, LR = 0.0001\n",
      "Epoch 364: cost = 0.022413108867978152, LR = 0.0001\n",
      "Epoch 365: cost = 0.022334796654745383, LR = 0.0001\n",
      "Epoch 366: cost = 0.02215213617309454, LR = 0.0001\n",
      "Epoch 367: cost = 0.02225200422428084, LR = 0.0001\n",
      "Epoch 368: cost = 0.022395544903984883, LR = 0.0001\n",
      "Epoch 369: cost = 0.022094355459760455, LR = 0.0001\n",
      "Epoch 370: cost = 0.02200606877678434, LR = 0.0001\n",
      "Epoch 371: cost = 0.021928468112412173, LR = 0.0001\n",
      "Epoch 372: cost = 0.022071854585419326, LR = 0.0001\n",
      "Epoch 373: cost = 0.021998632398288847, LR = 0.0001\n",
      "Epoch 374: cost = 0.021879518102195208, LR = 0.0001\n",
      "Epoch 375: cost = 0.02177839569140359, LR = 0.0001\n",
      "Epoch 376: cost = 0.021890627855551313, LR = 0.0001\n",
      "Epoch 377: cost = 0.021962833295281106, LR = 0.0001\n",
      "Epoch 378: cost = 0.021952864700622205, LR = 0.0001\n",
      "Epoch 379: cost = 0.021897834174477708, LR = 0.0001\n",
      "Epoch 380: cost = 0.021841433848152556, LR = 0.0001\n",
      "Epoch 381: cost = 0.021960090288371464, LR = 0.0001\n",
      "Epoch 382: cost = 0.021987275737400724, LR = 0.0001\n",
      "Epoch 383: cost = 0.021833732275554355, LR = 0.0001\n",
      "Epoch 384: cost = 0.022019346741418203, LR = 0.0001\n",
      "Epoch 385: cost = 0.02203483356915901, LR = 0.0001\n",
      "Epoch 386: cost = 0.021990156343314797, LR = 0.0001\n",
      "Epoch 387: cost = 0.02190058583191724, LR = 0.0001\n",
      "Epoch 388: cost = 0.021989402423563897, LR = 0.0001\n",
      "Epoch 389: cost = 0.021920676139447183, LR = 0.0001\n",
      "Epoch 390: cost = 0.02195555517593548, LR = 0.0001\n",
      "Epoch 391: cost = 0.022059299610298053, LR = 0.0001\n",
      "Epoch 392: cost = 0.02205307013611706, LR = 0.0001\n",
      "Epoch 393: cost = 0.021822111997141604, LR = 0.0001\n",
      "Epoch 394: cost = 0.02185125081274989, LR = 0.0001\n",
      "Epoch 395: cost = 0.021873085082976494, LR = 0.0001\n",
      "Epoch 396: cost = 0.02172015060569243, LR = 0.0001\n",
      "Epoch 397: cost = 0.021886699725267807, LR = 0.0001\n",
      "Epoch 398: cost = 0.02193934452775013, LR = 0.0001\n",
      "Epoch 399: cost = 0.021972429400553876, LR = 0.0001\n",
      "Epoch 400: cost = 0.021913758921578215, LR = 0.0001\n",
      "Epoch 401: cost = 0.021690074892620308, LR = 0.0001\n",
      "Epoch 402: cost = 0.02199497085504494, LR = 0.0001\n",
      "Epoch 403: cost = 0.021926822359190582, LR = 0.0001\n",
      "Epoch 404: cost = 0.022032506002953773, LR = 0.0001\n",
      "Epoch 405: cost = 0.02204949107294642, LR = 0.0001\n",
      "Epoch 406: cost = 0.02207925627682888, LR = 0.0001\n",
      "Epoch 407: cost = 0.022025496270885975, LR = 0.0001\n",
      "Epoch 408: cost = 0.02197979606673849, LR = 0.0001\n",
      "Epoch 409: cost = 0.022076375847222964, LR = 0.0001\n",
      "Epoch 410: cost = 0.022214230515223563, LR = 0.0001\n",
      "Epoch 411: cost = 0.022176858425878937, LR = 0.0001\n",
      "Epoch 412: cost = 0.02221365475884174, LR = 0.0001\n",
      "Epoch 413: cost = 0.022293213899700258, LR = 0.0001\n",
      "Epoch 414: cost = 0.02218256395326642, LR = 0.0001\n",
      "Epoch 415: cost = 0.022184194110674814, LR = 0.0001\n",
      "Epoch 416: cost = 0.022258855701614948, LR = 0.0001\n",
      "Epoch 417: cost = 0.02237303884806863, LR = 0.0001\n",
      "Epoch 418: cost = 0.02231361321834873, LR = 0.0001\n",
      "Epoch 419: cost = 0.02222641030860896, LR = 0.0001\n",
      "Epoch 420: cost = 0.022088461511477284, LR = 0.0001\n",
      "Epoch 421: cost = 0.022293326859646617, LR = 0.0001\n",
      "Epoch 422: cost = 0.022238788384630014, LR = 0.0001\n",
      "Epoch 423: cost = 0.022265285078432763, LR = 0.0001\n",
      "Epoch 424: cost = 0.022195433657184526, LR = 0.0001\n",
      "Epoch 425: cost = 0.022166232052911867, LR = 0.0001\n",
      "Epoch 426: cost = 0.02204531327070231, LR = 0.0001\n",
      "Epoch 427: cost = 0.02223993636456502, LR = 0.0001\n",
      "Epoch 428: cost = 0.022103229812782926, LR = 0.0001\n",
      "Epoch 429: cost = 0.02226225237683024, LR = 0.0001\n",
      "Epoch 430: cost = 0.02222434954028884, LR = 0.0001\n",
      "Epoch 431: cost = 0.02221048048561783, LR = 0.0001\n",
      "Epoch 432: cost = 0.022157894066054926, LR = 0.0001\n",
      "Epoch 433: cost = 0.022199249305925352, LR = 0.0001\n",
      "Epoch 434: cost = 0.022228938324022313, LR = 0.0001\n",
      "Epoch 435: cost = 0.02230501001990742, LR = 0.0001\n",
      "Epoch 436: cost = 0.0221311411303307, LR = 0.0001\n",
      "Epoch 437: cost = 0.022176989930717615, LR = 0.0001\n",
      "Epoch 438: cost = 0.022121732095109935, LR = 0.0001\n",
      "Epoch 439: cost = 0.02215197116558579, LR = 0.0001\n",
      "Epoch 440: cost = 0.02213286826515931, LR = 0.0001\n",
      "Epoch 441: cost = 0.02207490806504564, LR = 0.0001\n",
      "Epoch 442: cost = 0.022068768661304774, LR = 0.0001\n",
      "Epoch 443: cost = 0.02201196238211889, LR = 0.0001\n",
      "Epoch 444: cost = 0.022000493606244606, LR = 0.0001\n",
      "Epoch 445: cost = 0.021949873781548328, LR = 0.0001\n",
      "Epoch 446: cost = 0.021943478705874552, LR = 0.0001\n",
      "Epoch 447: cost = 0.021862967093409687, LR = 0.0001\n",
      "Epoch 448: cost = 0.02178736643033557, LR = 0.0001\n",
      "Epoch 449: cost = 0.021790359981109304, LR = 0.0001\n",
      "Epoch 450: cost = 0.02193381528247037, LR = 0.0001\n",
      "Epoch 451: cost = 0.02166772990005038, LR = 0.0001\n",
      "Epoch 452: cost = 0.021794501513424394, LR = 0.0001\n",
      "Epoch 453: cost = 0.021918578839883848, LR = 0.0001\n",
      "Epoch 454: cost = 0.0217844575595493, LR = 0.0001\n",
      "Epoch 455: cost = 0.021601748722379324, LR = 0.0001\n",
      "Epoch 456: cost = 0.021845719821155643, LR = 0.0001\n",
      "Epoch 457: cost = 0.021583408671901946, LR = 0.0001\n",
      "Epoch 458: cost = 0.021732663689670563, LR = 0.0001\n",
      "Epoch 459: cost = 0.021638649053728858, LR = 0.0001\n",
      "Epoch 460: cost = 0.02171213374557613, LR = 0.0001\n",
      "Epoch 461: cost = 0.021767938372828234, LR = 0.0001\n",
      "Epoch 462: cost = 0.02160349727797649, LR = 0.0001\n",
      "Epoch 463: cost = 0.021610877150222006, LR = 0.0001\n",
      "Epoch 464: cost = 0.021557021637605336, LR = 0.0001\n",
      "Epoch 465: cost = 0.02140378423185756, LR = 0.0001\n",
      "Epoch 466: cost = 0.021669322539018036, LR = 0.0001\n",
      "Epoch 467: cost = 0.021480090725673206, LR = 0.0001\n",
      "Epoch 468: cost = 0.021503037140873326, LR = 0.0001\n",
      "Epoch 469: cost = 0.021562009216159257, LR = 0.0001\n",
      "Epoch 470: cost = 0.021276184327081015, LR = 0.0001\n",
      "Epoch 471: cost = 0.021380935412090286, LR = 0.0001\n",
      "Epoch 472: cost = 0.021320859532283486, LR = 0.0001\n",
      "Epoch 473: cost = 0.0213011463588208, LR = 0.0001\n",
      "Epoch 474: cost = 0.021400438936755986, LR = 0.0001\n",
      "Epoch 475: cost = 0.021218007084264946, LR = 0.0001\n",
      "Epoch 476: cost = 0.02139931124111662, LR = 0.0001\n",
      "Epoch 477: cost = 0.021225683767950018, LR = 0.0001\n",
      "Epoch 478: cost = 0.02113242358887439, LR = 0.0001\n",
      "Epoch 479: cost = 0.021105135513955642, LR = 0.0001\n",
      "Epoch 480: cost = 0.021281241459283524, LR = 0.0001\n",
      "Epoch 481: cost = 0.021072900511014542, LR = 0.0001\n",
      "Epoch 482: cost = 0.021210752697423025, LR = 0.0001\n",
      "Epoch 483: cost = 0.021226818864718163, LR = 0.0001\n",
      "Epoch 484: cost = 0.02135828142679523, LR = 0.0001\n",
      "Epoch 485: cost = 0.021399671371839773, LR = 0.0001\n",
      "Epoch 486: cost = 0.021569846721082735, LR = 0.0001\n",
      "Epoch 487: cost = 0.021510497659241803, LR = 0.0001\n",
      "Epoch 488: cost = 0.021729694492564473, LR = 0.0001\n",
      "Epoch 489: cost = 0.021537536338002674, LR = 0.0001\n",
      "Epoch 490: cost = 0.02173420777966359, LR = 0.0001\n",
      "Epoch 491: cost = 0.021785686810363553, LR = 0.0001\n",
      "Epoch 492: cost = 0.021707658856875808, LR = 0.0001\n",
      "Epoch 493: cost = 0.021935231380625857, LR = 0.0001\n",
      "Epoch 494: cost = 0.02181591932573619, LR = 0.0001\n",
      "Epoch 495: cost = 0.021762944599626282, LR = 0.0001\n",
      "Epoch 496: cost = 0.021844053535671724, LR = 0.0001\n",
      "Epoch 497: cost = 0.021582054134598634, LR = 0.0001\n",
      "Epoch 498: cost = 0.02172013932559871, LR = 0.0001\n",
      "Epoch 499: cost = 0.021543665647376458, LR = 0.0001\n"
     ]
    }
   ],
   "source": [
    "W_1, B_1, W_2, B_2 = train(500, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f094dd2-8bfb-412b-8615-1d607fba83a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.34% correct\n",
      "9534/10000 correct\n"
     ]
    }
   ],
   "source": [
    "sample_size = 10000\n",
    "X_sample = x_test[:sample_size]\n",
    "X_sample = x_test[:sample_size]\n",
    "predictions, probabilities = predict(X_sample, W_1, B_1, W_2, B_2)\n",
    "\n",
    "correct = 0\n",
    "for i in range(sample_size):\n",
    "    correct += (predictions[i] == x_test_labels[i])\n",
    "\n",
    "print(f\"{correct/sample_size * 100}% correct\" )\n",
    "print(f\"{correct}/{sample_size} correct\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a8c81-cfc6-4ce3-97ea-4e1bf509162e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
