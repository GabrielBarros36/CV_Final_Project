{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912943cb-a201-4af2-9fc1-dea4fe9416ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An attempt to make Neural net w/ more than 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a65f732-1763-44c2-95c1-99bdb9540f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7afba83-6f8f-4f61-99f9-394c241d2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 785 cols bc of labels row - only 28*28 = 784 pixels\n",
    "data = pd.read_csv('mnist_train.csv')\n",
    "data_test = pd.read_csv('mnist_test.csv')\n",
    "\n",
    "data = np.array(data)\n",
    "data_test = np.array(data_test)\n",
    "\n",
    "data = data.T\n",
    "data_test = data_test.T\n",
    "\n",
    "def preprocess_data(X):\n",
    "    \"\"\"Preprocess the input data\"\"\"\n",
    "    # Scale pixels to [0, 1] range\n",
    "    X = X / 255.0\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d11f1c5b-28fd-4972-82aa-2f8a304ab707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 784)\n",
      "[7 2 1 ... 4 5 6]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_train = data[1:data[0].size].T # 2D Array: each row (array) is a picture\n",
    "x_test = data_test[1:data[0].size].T # 2D Array: each row (array) is a picture\n",
    "x_train = preprocess_data(x_train)\n",
    "x_test = preprocess_data(x_test)\n",
    "x_labels = data[0] # Array: each number is the correct label for the corresponding index in x_train\n",
    "x_test_labels = data_test[0]\n",
    "print(x_train.shape)\n",
    "print(x_test_labels)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca8c430-3e52-46aa-b5f5-2d4f78cf09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters for every layer\n",
    "# Weights & biases\n",
    "# 3 hidden layers w/ 32, 32, 16 neurons respectively\n",
    "def init_params():\n",
    "    W_1 = np.random.randn(32, 784) * np.sqrt(2.0/784) # Edges from layer 1 to layer 2\n",
    "    B_1 = np.zeros(32) # Biases for layer 2\n",
    "\n",
    "    W_2 = np.random.randn(32, 32) * np.sqrt(2.0/32) # Edges from layer 2 to layer 3\n",
    "    B_2 = np.zeros(32) # Biases for layer 3\n",
    "\n",
    "    W_3 = np.random.randn(32, 32) * np.sqrt(2.0/32) # Edges from layer 3 to layer 4\n",
    "    B_3 = np.zeros(32) # Biases for layer 4\n",
    "    \n",
    "    W_4 = np.random.randn(10, 32) * np.sqrt(2.0/16) # Edges from layer 4 to layer 5\n",
    "    B_4 = np.zeros(10) # Biases for layer 5\n",
    "    return W_1, B_1, W_2, B_2, W_3, B_3, W_4, B_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e31262-3784-492c-947b-1c799225a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    # Ensure input is at least 1D\n",
    "    Z = np.atleast_1d(Z)\n",
    "    \n",
    "    # Shift values by max for numerical stability\n",
    "    Z_shifted = Z - np.max(Z, axis=-1, keepdims=True)\n",
    "    \n",
    "    # Avoid overflow\n",
    "    exp_Z = np.exp(np.clip(Z_shifted, -709, 709))  # np.log(np.finfo(np.float64).max) â‰ˆ 709\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    sum_exp_Z = np.sum(exp_Z, axis=-1, keepdims=True)\n",
    "    sum_exp_Z = np.maximum(sum_exp_Z, np.finfo(float).tiny)\n",
    "    \n",
    "    softmax_output = exp_Z / sum_exp_Z\n",
    "    \n",
    "    # Ensure probabilities sum to 1\n",
    "    softmax_output = softmax_output / np.sum(softmax_output, axis=-1, keepdims=True)\n",
    "    \n",
    "    return softmax_output\n",
    "\n",
    "# Cross-entropy cost function\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    # y_true is a one-hot encoded vector (e.g., [0, 1, 0, ...])\n",
    "    # y_pred is the softmax output\n",
    "    epsilon = 1e-10  # To avoid log(0)\n",
    "    return -np.sum(y_true * np.log(y_pred + epsilon))  # Sum over classes\n",
    "\n",
    "# Cost function\n",
    "def get_cost(Z_2, i):\n",
    "    error_arr = np.zeros(10)\n",
    "    error_arr[x_labels[i]] = 1 # Corresponding to one_picture\n",
    "    cost = cross_entropy_loss(error_arr, Z_2)\n",
    "    return cost, error_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3131e1c-28a9-4b9a-94bd-a25d9281c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Propagation\n",
    "# Z_1: neurons in hidden layer 1\n",
    "# Z_2: neurons in hidden layer 2\n",
    "# Z_3: neurons in hidden layer 3\n",
    "# Z_4: neurons in output layer\n",
    "\n",
    "def forward_prop(i, W_1, B_1, W_2, B_2, W_3, B_3, W_4, B_4):\n",
    "    one_picture = x_train[i] # A single sample picture\n",
    "    \n",
    "    Z_1 = W_1.dot(one_picture) + B_1\n",
    "    Z_1 = ReLU(Z_1)\n",
    "\n",
    "    Z_2 = W_2.dot(Z_1) + B_2\n",
    "    Z_2 = ReLU(Z_2)\n",
    "\n",
    "    Z_3 = W_3.dot(Z_2) + B_3\n",
    "    Z_3 = ReLU(Z_3)\n",
    "    \n",
    "    Z_4 = W_4.dot(Z_3) + B_4\n",
    "    Z_4 = softmax(Z_4)\n",
    "\n",
    "\n",
    "    \n",
    "    return Z_1, Z_2, Z_3, Z_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dcfb96c-6fc1-4ed3-9b50-5868b5a23ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "def back_prop(Z_1, Z_2, W_2, Z_3, W_3, Z_4, W_4, i):\n",
    "    one_picture = x_train[i]\n",
    "    error_arr = get_cost(Z_4, i)[1]\n",
    "\n",
    "    dZ_4 = Z_4 - error_arr\n",
    "    dW_4 = np.outer(dZ_4, Z_3)\n",
    "    dB_4 = dZ_4\n",
    "\n",
    "    dZ_3 = W_4.T.dot(dZ_4)\n",
    "    dZ_3 *= (Z_3 > 0)\n",
    "    dW_3 = np.outer(dZ_3, Z_2)\n",
    "    dB_3 = dZ_3\n",
    "\n",
    "    dZ_2 = W_3.T.dot(dZ_3)\n",
    "    dZ_2 *= (Z_2 > 0)\n",
    "    dW_2 = np.outer(dZ_2, Z_1)\n",
    "    dB_2 = dZ_2\n",
    "\n",
    "    dZ_1 = W_2.T.dot(dZ_2)\n",
    "    dZ_1 *= (Z_1 > 0)\n",
    "    dW_1 = np.outer(dZ_1, one_picture)\n",
    "    dB_1 = dZ_1\n",
    "\n",
    "    return dW_1, dB_1, dZ_1, dW_2, dB_2, dZ_2, dW_3, dB_3, dZ_3, dW_4, dB_4, dZ_4\n",
    "    \"\"\"\n",
    "    one_picture = x_train[i]\n",
    "    error_arr = get_cost(Z_2, i)[1]\n",
    "    \n",
    "    dZ_2 = Z_2 - error_arr\n",
    "    dW_2 = np.outer(dZ_2, Z_1)\n",
    "    dB_2 = dZ_2\n",
    "    \n",
    "    dZ_1 = W_2.T.dot(dZ_2)\n",
    "    dZ_1 *= (Z_1 > 0)\n",
    "    dW_1 = np.outer(dZ_1, one_picture)\n",
    "    dB_1 = dZ_1\n",
    "    \n",
    "    return dW_1, dB_1, dZ_1, dW_2, dB_2, dZ_2\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6d34ec3-1ebe-4d47-9694-5253192dcd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters\n",
    "def update_params(W_4, B_4, W_3, B_3, W_2, B_2, W_1, B_1, dW_4, dB_4, dW_3, dB_3, dW_2, dB_2, dW_1, dB_1, learning_rate):\n",
    "\n",
    "    W_4 -= dW_4 * learning_rate\n",
    "    B_4 -= dB_4 * learning_rate\n",
    "    W_3 -= dW_3 * learning_rate\n",
    "    B_3 -= dB_3 * learning_rate\n",
    "    \n",
    "    W_2 -= dW_2 * learning_rate\n",
    "    B_2 -= dB_2 * learning_rate\n",
    "    W_1 -= dW_1 * learning_rate\n",
    "    B_1 -= dB_1 * learning_rate\n",
    "    return W_1, B_1, W_2, B_2, W_3, B_3, W_4, B_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2eeef7a-9010-49e6-9d75-436ded1a0ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, learning_rate):\n",
    "    train_start = time.time()\n",
    "    W_1, B_1, W_2, B_2, W_3, B_3, W_4, B_4 = init_params()\n",
    "    leng = x_train.shape[0]\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        #np.random.shuffle(x_train)\n",
    "\n",
    "        #learning_rate *= 0.9 # Varying learning rate    \n",
    "        \n",
    "        iteration = 0\n",
    "        for j in range(leng):\n",
    "            iteration = j\n",
    "            Z_1, Z_2, Z_3, Z_4 = forward_prop(j, W_1, B_1, W_2, B_2, W_3, B_3, W_4, B_4)\n",
    "            dW_1, dB_1, dZ_1, dW_2, dB_2, dZ_2, dW_3, dB_3, dZ_3, dW_4, dB_4, dZ_4 = back_prop(Z_1, Z_2, W_2, Z_3, W_3, Z_4, W_4, j)\n",
    "            W_1, B_1, W_2, B_2, W_3, B_3, W_4, B_4 = update_params(W_4, B_4, W_3, B_3, W_2, B_2, W_1, B_1, dW_4, dB_4, dW_3, dB_3, dW_2, dB_2, dW_1, dB_1, learning_rate)    \n",
    "        if i % 1 == 0:\n",
    "            print(f\"Epoch {i}: cost = {get_cost(Z_4, iteration)[0]}, LR = {learning_rate}\")\n",
    "    train_end = time.time()\n",
    "    print(f\"Total training time: {(train_end-train_start)} seconds\")\n",
    "    return W_1, B_1, W_2, B_2, W_3, B_3,  W_4, B_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c5af1f9-b68c-4894-ba75-bea683f5663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W_1, B_1, W_2, B_2, W_3, B_3, W_4, B_4):\n",
    "    \"\"\"\n",
    "    Make predictions for input images\n",
    "    \n",
    "    Parameters:\n",
    "    X: numpy array of shape (n_samples, 784) - input images\n",
    "    Returns: tuple (predictions, probabilities)\n",
    "    - predictions: predicted digit for each image\n",
    "    - probabilities: softmax probabilities for each digit\n",
    "    \"\"\"\n",
    "    # Ensure input is properly scaled\n",
    "    X = X / 255.0 if X.max() > 1 else X\n",
    "    \n",
    "    # Forward pass\n",
    "    Z_1 = X.dot(W_1.T) + B_1\n",
    "    A_1 = np.maximum(0, Z_1)  # ReLU\n",
    "\n",
    "    Z_2 = A_1.dot(W_2.T) + B_2\n",
    "    A_2 = np.maximum(0, Z_2)\n",
    "\n",
    "    Z_3 = A_2.dot(W_3.T) + B_3\n",
    "    A_3 = np.maximum(0, Z_3)\n",
    "    \n",
    "    Z_4 = A_3.dot(W_4.T) + B_4\n",
    "    probabilities = softmax(Z_4)\n",
    "    \n",
    "    # Get predicted digit (class with highest probability)\n",
    "    predictions = np.argmax(probabilities, axis=1)\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea246f30-3391-436f-a010-c6c9f30374ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: cost = 0.022025796551268677, LR = 0.001\n",
      "Epoch 1: cost = 0.025557602592742215, LR = 0.001\n",
      "Epoch 2: cost = 0.024190802963432678, LR = 0.001\n",
      "Epoch 3: cost = 0.011633161907439163, LR = 0.001\n",
      "Epoch 4: cost = 0.007933217366395006, LR = 0.001\n",
      "Total training time: 22.28968381881714 seconds\n"
     ]
    }
   ],
   "source": [
    "W_1, B_1, W_2, B_2, W_3, B_3,  W_4, B_4 = train(5, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e06c9c5-e6dd-4111-b2eb-b43fcb79bc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.16% correct\n",
      "9616/10000 correct\n",
      "Time elapsed for inference: 0.06954383850097656 seconds\n"
     ]
    }
   ],
   "source": [
    "sample_size = 10000\n",
    "X_sample = x_test[:sample_size]\n",
    "X_sample = x_test[:sample_size]\n",
    "\n",
    "inf_start = time.time()\n",
    "\n",
    "predictions, probabilities = predict(X_sample, W_1, B_1, W_2, B_2, W_3, B_3, W_4, B_4)\n",
    "\n",
    "correct = 0\n",
    "for i in range(sample_size):\n",
    "    correct += (predictions[i] == x_test_labels[i])\n",
    "\n",
    "inf_end = time.time()\n",
    "\n",
    "print(f\"{correct/sample_size * 100}% correct\" )\n",
    "print(f\"{correct}/{sample_size} correct\" )\n",
    "print(f\"Time elapsed for inference: {(inf_end-inf_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447471ba-9a6d-45c8-93e6-aef275a9237e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
